{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb5e35d",
   "metadata": {},
   "source": [
    "# Classification Model Comparison\n",
    "\n",
    "This notebook trains a simple classifier to predict the label of a transaction using:\n",
    "1. The raw `description`\n",
    "2. The tokenized `description` from `replace_tokens()`\n",
    "\n",
    "The goal is to demonstrate how preprocessing affects model generalization and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faabe802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea46864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import replace_tokens\n",
    "\n",
    "df_raw = pd.read_csv(\"../data/transactions.csv\")\n",
    "df_tokenized = df_raw.copy()\n",
    "df_tokenized['description'] = df_tokenized.apply(lambda row: replace_tokens(row['description'], row['label']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556988c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, text_col, label_col='label'):\n",
    "    X = df[text_col]\n",
    "    y = df[label_col]\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Vectorize\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Train\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    print(f\"Results using: {text_col}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4a9671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using: description\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   ATM and Cash Withdrawal       1.00      1.00      1.00         1\n",
      "                   Alcohol       0.00      0.00      0.00         2\n",
      "            Auto Insurance       1.00      1.00      1.00         1\n",
      "     Bank Charges and Fees       0.78      1.00      0.88        14\n",
      "             Bank Transfer       0.50      0.50      0.50         2\n",
      "    Cellular Data Purchase       1.00      1.00      1.00         3\n",
      "                  Clothing       0.00      0.00      0.00         2\n",
      "                    Coffee       1.00      1.00      1.00         2\n",
      "               Debit Order       1.00      1.00      1.00         2\n",
      "                  Donation       0.00      0.00      0.00         1\n",
      "                Eating Out       0.55      0.92      0.69        12\n",
      "Electronics and Appliances       0.00      0.00      0.00         1\n",
      "      Fast Food & Takeouts       1.00      0.50      0.67         2\n",
      "                      Fuel       0.00      0.00      0.00         1\n",
      "         General Insurance       1.00      1.00      1.00         1\n",
      "    General Loan Repayment       0.00      0.00      0.00         1\n",
      "         General Purchases       0.43      0.38      0.40         8\n",
      "                 Groceries       0.56      1.00      0.71         5\n",
      "        Health and Medical       0.00      0.00      0.00         1\n",
      "       Holidays and Travel       1.00      1.00      1.00         1\n",
      "           Home and Garden       0.00      0.00      0.00         1\n",
      "    Insufficient Funds Fee       1.00      1.00      1.00        11\n",
      "         Interest Received       1.00      0.50      0.67         2\n",
      "        Interest Repayment       1.00      1.00      1.00         1\n",
      "               Investments       1.00      1.00      1.00         1\n",
      "            Life Insurance       0.00      0.00      0.00         0\n",
      "           Online Purchase       0.00      0.00      0.00         1\n",
      "                   Parking       0.00      0.00      0.00         1\n",
      "                    Refund       0.00      0.00      0.00         1\n",
      "          Savings Transfer       1.00      1.00      1.00         3\n",
      "             Subscriptions       1.00      1.00      1.00         5\n",
      "         Tobacco & Smoking       0.00      0.00      0.00         1\n",
      "\n",
      "                  accuracy                           0.75        91\n",
      "                 macro avg       0.53      0.52      0.52        91\n",
      "              weighted avg       0.67      0.75      0.69        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(df_raw, 'description')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab4e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using: description\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   ATM and Cash Withdrawal       1.00      1.00      1.00         1\n",
      "                   Alcohol       0.00      0.00      0.00         2\n",
      "            Auto Insurance       1.00      1.00      1.00         1\n",
      "     Bank Charges and Fees       0.78      1.00      0.88        14\n",
      "             Bank Transfer       0.50      0.50      0.50         2\n",
      "    Cellular Data Purchase       1.00      1.00      1.00         3\n",
      "                  Clothing       0.00      0.00      0.00         2\n",
      "                    Coffee       1.00      1.00      1.00         2\n",
      "               Debit Order       1.00      1.00      1.00         2\n",
      "                  Donation       0.00      0.00      0.00         1\n",
      "                Eating Out       1.00      1.00      1.00        12\n",
      "Electronics and Appliances       0.00      0.00      0.00         1\n",
      "      Fast Food & Takeouts       1.00      0.50      0.67         2\n",
      "                      Fuel       1.00      1.00      1.00         1\n",
      "         General Insurance       1.00      1.00      1.00         1\n",
      "    General Loan Repayment       0.00      0.00      0.00         1\n",
      "         General Purchases       0.50      1.00      0.67         8\n",
      "                 Groceries       0.83      1.00      0.91         5\n",
      "        Health and Medical       0.00      0.00      0.00         1\n",
      "       Holidays and Travel       1.00      1.00      1.00         1\n",
      "           Home and Garden       0.00      0.00      0.00         1\n",
      "    Insufficient Funds Fee       1.00      1.00      1.00        11\n",
      "         Interest Received       1.00      0.50      0.67         2\n",
      "        Interest Repayment       1.00      1.00      1.00         1\n",
      "               Investments       1.00      1.00      1.00         1\n",
      "            Life Insurance       0.00      0.00      0.00         0\n",
      "           Online Purchase       0.00      0.00      0.00         1\n",
      "                   Parking       0.00      0.00      0.00         1\n",
      "                    Refund       0.00      0.00      0.00         1\n",
      "          Savings Transfer       1.00      1.00      1.00         3\n",
      "             Subscriptions       1.00      1.00      1.00         5\n",
      "         Tobacco & Smoking       1.00      1.00      1.00         1\n",
      "\n",
      "                  accuracy                           0.84        91\n",
      "                 macro avg       0.61      0.61      0.60        91\n",
      "              weighted avg       0.77      0.84      0.79        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(df_tokenized, 'description')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad65a636",
   "metadata": {},
   "source": [
    "## Classification Model Results Summary\n",
    "\n",
    "### Table 1: Overall Model Performance (Raw vs. Tokenized)\n",
    "\n",
    "| Metric                | Raw Descriptions | Tokenized Descriptions | Improvement |\n",
    "|-----------------------|------------------|------------------------|-------------|\n",
    "| **Accuracy**          | 0.75             | 0.84                   | **+0.09**  |\n",
    "| **Macro F1-Score**    | 0.52             | 0.60                   | **+0.08**  |\n",
    "| **Weighted F1-Score** | 0.69             | 0.79                   | **+0.10**  |\n",
    "\n",
    "---\n",
    "\n",
    "### Table 2: Class-Level F1 Score Improvement (Selected Labels)\n",
    "\n",
    "| Label                 | F1 (Raw) | F1 (Tokenized) | Improvement |\n",
    "|-----------------------|----------|----------------|-------------|\n",
    "| **Eating Out**         | 0.69     | 1.00           | **+0.31**  |\n",
    "| **Groceries**          | 0.71     | 0.91           | **+0.20**  |\n",
    "| **Fuel**               | 0.00     | 1.00           | **+1.00**  |\n",
    "| **General Purchases**  | 0.40     | 0.67           | **+0.27**  |\n",
    "\n",
    " These classes benefited directly from semantic token replacement, where specific vendor/location strings were replaced with learnable class tokens.\n",
    "\n",
    "---\n",
    "\n",
    "### Table 3: Token Replacements and Their Purpose\n",
    "\n",
    "| Token         | Replaces Example Strings           | Purpose                              |\n",
    "|---------------|------------------------------------|--------------------------------------|\n",
    "| `[grocers]`   | Woolworths, Checkers, PnP, etc.    | Reduces vendor name sparsity         |\n",
    "| `[restaurant]`| Uber Eats, Steers, KFC, etc.       | Generalizes food vendors             |\n",
    "| `[garage]`    | Engen, Sasol, Shell, etc.          | Standardizes fuel-related terms      |\n",
    "| `[location]`  | Craighall, Mitchell Park, etc.     | Removes low-frequency location noise |\n",
    "| `[date]`      | `* 23 Sep`, `* 14 Oct`, etc.       | Removes one-off date tokens          |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The token replacement strategy led to clear improvements in model performance, especially for categories most affected by sparse, vendor-specific naming.\n",
    "\n",
    "By abstracting vendors, dates, and locations into general semantic tokens, the model was able to generalize better, particularly on labels like `Eating Out`, `Groceries`, and `Fuel`.\n",
    "\n",
    "These results validate that thoughtful preprocessing can significantly enhance classification accuracy on noisy transactional text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f00d7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
